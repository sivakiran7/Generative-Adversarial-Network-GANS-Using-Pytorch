# -*- coding: utf-8 -*-
"""ImageGenerationusingGANS.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bCfwmCCVPZQAoceQScNsOfayPhI8JMSX

``GANS`` : A type of deep learning architecture that uses two competing neural networks a generator and a discriminator to create new data instances that resemble a training data
"""

!pip install opendatasets --upgrade --quiet

import opendatasets as od

dataset_url = 'https://www.kaggle.com/datasets/splcher/animefacedataset'
od.download(dataset_url)

import os

DATA_DIR = './animefacedataset'
print(os.listdir(DATA_DIR))

print(os.listdir(DATA_DIR + '/images')[:10])

# load the dataset using the image folder class from torchvision. also resize the images to 64X64 values with a mean & standard deviation 0.5

from torch.utils.data import DataLoader
from torchvision.datasets import ImageFolder
import torchvision.transforms as T

image_size = 64
batch_size = 128
stats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5) # mean and standard deviation

# creating a training dataset for model training

train_ds = ImageFolder(DATA_DIR, transform=T.Compose([
    T.Resize(image_size),
    T.CenterCrop(image_size),
    T.ToTensor(),
    T.Normalize(*stats)]))

train_dl = DataLoader(train_ds,
                      batch_size, # dividing the dataset into batchsizes
                      shuffle=True, # shuffling the dataset for not memorizing the dataset patterns
                      num_workers=3,  # no of cpu cores to work for training a dataset
                      pin_memory=True)

# Commented out IPython magic to ensure Python compatibility.
# create a helper function to denormalize the image tensors

import torch
from torchvision.utils import make_grid
import matplotlib.pyplot as plt
# %matplotlib inline

def denorm(img_tensors):
  return img_tensors * stats[1][0] + stats[0][0]

def show_images(images, nmax=64):
  fig, ax = plt.subplots(figsize=(8, 8))
  ax.set_xticks([]); ax.set_yticks([])
  ax.imshow(make_grid(denorm(images.detach()[:nmax]), nrow=8).permute(1, 2, 0)) # permute is used to change the dimensions of the image in pytorch the sequence is (colour, height , width) for matplot we need colour at the last position ( height, wifth, colour)

def show_batch(dl, nmax=64):
  for images, _ in dl:
    show_images(images, nmax)
    break

show_batch(train_dl)

"""**using a GPU**:

to seamlessly use a gpu if one is available we  define a couple of helper functions to move our model data to the gpu if one is available.

"""

def get_default_device():
  if torch.cuda.is_available():
    return torch.device('cuda')
  else:
    return torch.device('cpu')

# transfering data into the gpu

def to_device(data, device):
  if isinstance(data, (list,tuple)):
    return [to_device(x, device) for x in data]
  return data.to(device, non_blocking=True)

class DeviceDataLoader():
  """wrap a dataloader to move data to a device"""
  def __init__(self, dl, device):
    self.dl = dl
    self.device = device

  def __iter__(self):
    """Yield a batch of data after moving it to device"""
    for b in self.dl:
      yield to_device(b, self.device)

  def __len__(self):
    """Number of batches"""
    return len(self.dl)

device = get_default_device()
device

# we can move our training dataloader using Devicedataloader for automatically transfering batches of data to the GPU

train_dl =DeviceDataLoader(train_dl, device)

"""**Discriminator Network**

 The discriminator takes an image as input and tries to classify it as real or generated. in sense its like other neural network . we"ll use a convolutional neural network which outputs a single number output for every image.

 it is often called as binary classification
"""

import torch.nn as nn

discriminator = nn.Sequential(

    # input: 3 x 64 x 64
    nn.Conv2d(3,64,kernel_size=4,stride=2,padding=1,bias=False),
    nn.BatchNorm2d(64),
    nn.LeakyReLU(0.2,inplace=True),

    # out: 64 x 32 x 32

    nn.Conv2d(64,128,kernel_size=4,stride=2,padding=1,bias=False),
    nn.BatchNorm2d(128),
    nn.LeakyReLU(0.2,inplace=True),
    #out: 128 x 16 x 16

    nn.Conv2d(128,256,kernel_size=4,stride=2,padding=1,bias=False),
    nn.BatchNorm2d(256),
    nn.LeakyReLU(0.2,inplace=True),
    # out: 256 x 8 x 8

    nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1, bias=False),
    nn.BatchNorm2d(512),
    nn.LeakyReLU(0.2, inplace=True),
    # out: 512 x 4 x 4

    nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=0, bias=False),
    # out: 1 x 1 x 1

    nn.Flatten(),
    nn.Sigmoid()  # sigmoid function is used in neural networks to map any real valued input into a range of 0 to 1
)

# leaky Relu : it is used to address the "Dying Relu problem" by allowing a small, non-zero gradient for negative inputs
# which prevents neurons from becoming permanently inactive during training

# move the discriminator model to the chosen device

discriminator = to_device(discriminator, device)

"""# `` Generator Network ``

the input to the generator is typically a vector or a matrix of random numbers which is used as a seed for generating an image. the generator will convert a latent tensor of shape (128, 1, 1) into an image of shape 3 x 28 x 28.




"""

latent_size= 128

# the latent dimension refers to a low-dimensional fixed size vector of random numbers that serves as the input to the generator
# the generator learns to map these latent vectors to high dimensional data samples such as image by transforming them from the latent space to data space

generator = nn.Sequential(
    # in : latent_size x 1 x 1

    nn.ConvTranspose2d(latent_size, 512, kernel_size=4, stride=1, padding=0, bias=False),
    nn.BatchNorm2d(512),
    nn.ReLU(True),
    # out: 512 x 4 x 4

    nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=False),
    nn.BatchNorm2d(256),
    nn.ReLU(True),
    # out: 256 x 8 x 8

    nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False),
    nn.BatchNorm2d(128),
    nn.ReLU(True),
    # out: 128 x 16 x 16

    nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False),
    nn.BatchNorm2d(64),
    nn.ReLU(True),
    # out: 64 x 32 x 32

    nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1, bias=False),
    nn.Tanh()
    # out: 3 x 64 x 64
)

# creating a random latent tensors

xb =torch.randn(batch_size, latent_size, 1, 1)
print(xb.shape)
fake_images = generator(xb)
print(fake_images.shape)
show_images(fake_images)

# move the generator to the chosen device

generator = to_device(generator, device)

"""**Discriminator Training**

Since the discriminator is a binary classification model we can use the binary cross entropy loss function to quantify how well it is able to differentiate between real and generated images

##**Binary Cross entropy** :
A common loss function in machine learning for binary classification problems measuring the dissimilarity between predicted probabilities and true binary labels.
"""

# training the discriminator

def train_discriminator(real_images, opt_d):
  # clear discriminator gradients
  opt_d.zero_grad()

  # pass real images through discriminator
  real_preds = discriminator(real_images)
  real_targets = torch.ones(real_images.size(0),1,device=device)
  real_loss = F.binary_cross_entropy(real_preds, real_targets)
  real_score = torch.mean(real_preds).item() # average of the real images

  # generate fake images
  latent = torch.randn(batch_size, latent_size, 1, 1, device=device)
  fake_images = generator(latent)

  # pass fake images through discriminator
  fake_targets = torch.zeros(fake_images.size(0),1,device=device)
  fake_preds = discriminator(fake_images)
  fake_loss = F.binary_cross_entropy(fake_preds, fake_targets)
  fake_score = torch.mean(fake_preds).item()

  # update discriminator weights
  loss = real_loss + fake_loss
  loss.backward()
  opt_d.step()
  return loss.item(), real_score, fake_score

# training generator

def train_generator(opt_g):

  #clear generator gradients
  opt_g.zero_grad()

  # generate fake images
  latent = torch.randn(batch_size, latent_size, 1, 1, device=device)
  fake_images = generator(latent)

  # try to fool the discriminator
  preds = discriminator(fake_images)
  targets = torch.ones(batch_size, 1, device=device)
  loss = F.binary_cross_entropy(preds, targets)

  # update generator weights
  loss.backward()
  opt_g.step()

  return loss.item()

"""create a directory where we can save intermediate outputs from the generator to visually inscept the progress of the model"""

from torchvision.utils import save_image

sample_dir ='generated'
os.makedirs(sample_dir, exist_ok=True)

def save_samples(index, latent_tensors, show=True):
  fake_images = generator(latent_tensors) # genetrate fake images
  fake_fname = 'generated-images-{0:0=4d}.png'.format(index) # construct a file name
  save_image(denorm(fake_images), os.path.join(sample_dir, fake_fname), nrow=8) # save the image at a particular directory
  print('Saving', fake_fname)
  if show:
    fig, ax = plt.subplots(figsize=(8, 8))
    ax.set_xticks([]); ax.set_yticks([])
    ax.imshow(make_grid(fake_images.cpu().detach(), nrow=8).permute(1, 2, 0))

"""use a det of input vectors to the generator to see how the individual generated images evolve over time"""

fixed_latent = torch.randn(64, latent_size, 1, 1, device=device)

save_samples(0, fixed_latent)

from tqdm.notebook import tqdm
import torch.nn.functional as F

def fit(epochs, lr, start_indx=1):
  torch.cuda.empty_cache() # remove unused data in gpu

  # losses and scores
  losses_g = []
  losses_d = []
  real_scores = []
  fake_scores = []

  # create optimizers
  opt_d = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999)) # change the weigths of discriminator
  opt_g = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999)) # change the weights of generator

  for epoch in range(epochs):
    for real_images, _ in tqdm(train_dl):
      # train discriminator
      loss_d, real_score, fake_score = train_discriminator(real_images, opt_d)
      # train generator
      loss_g = train_generator(opt_g)

    # record losses & scores
    losses_g.append(loss_g)
    losses_d.append(loss_d)
    real_scores.append(real_score)
    fake_scores.append(fake_score)

    # log losses and scores(last batch)
    print("Epoch [{}/{}], loss_g: {:.4f}, loss_d: {:.4f}, real_score: {:.4f}, fake_score: {:.4f}".format(
        epoch+1, epochs, loss_g, loss_d, real_score, fake_score))

    # save generated images
    save_samples(epoch+start_indx, fixed_latent, show=False)

  return losses_g, losses_d, real_scores, fake_scores

# hyper parameters

lr=0.0002
epochs =10

history = fit(epochs, lr)

losses_g, losses_d, real_scores, fake_scores = history

"""we can visualize the training process by combining the sample images generated after each epoch into a video using open cv"""

import cv2
import os

vid_fname = 'gans_training.avi'

files = [os.path.join(sample_dir, f) for f in os.listdir(sample_dir) if 'generated' in f]
files.sort()

out = cv2.VideoWriter(vid_fname,cv2.VideoWriter_fourcc(*'MP4V'), 1, (530,530))
[out.write(cv2.imread(fname)) for fname in files]
out.release()







